---
output:
  html_document: default
  pdf_document: default
---

Tutorial by Matthew Lober, Scott Macchia, and Selena Alvarado.

We are using a dataset in which each entity represents a FIFA 2019 player, and the attributes examine the players' statistics and biological features. Throughout this tutorial we will be manipulating this data set in different ways to show different statistics about players in the FIFA 2019 game. 

This dataset comes with 90 attributes. In order to choose which attributes we will be analyzing, use the tidy::select() function to decide which attributes are displayed per row.

A key function that you will see used here and in many other parts of this tutorial is the piping function, %>%. This function takes a dataframe on the left handside, and uses that dataframe as the first argument for the function called on the right hand side. It is very useful for compounding functions one after another on an altered dataframe.

Lastly, using the head() function, you can view the first few rows of your dataframe.

```{r read_csv, warning = FALSE}
library(tidyverse)
data <- read_csv("data.csv")

# a table containing each player and their biological information
fifa_bio <- data %>%
  select(ID, Name, Age, Club, Value, Wage, `Body Type`, Position, Height, Weight)

# a table containing each player and their playing statistics
fifa_stats <- data %>%
  select(ID, Name, BallControl, Dribbling, Strength, SprintSpeed, Acceleration, Interceptions, Stamina, 
         Vision, Marking, Balance)

# displays the first 6 rows of the fifa_stats table
fifa_stats %>% head()

```

With close to 20,000 entries, we may only want to view a few rows at once. The first way to do so is by using the slice() function. In this function, you provide a dataframe and which rows you would like to see, either by using a range "1:n", explicitly stating which rows you would like to see "c(1, 2, 5, 7)", or some other way of determining a row using seq() as an argument.
```{r slice_ex}

fifa_bio %>%
  slice(1:7)

```

You may want to select certain rows more specifically, perhaps by which team they play for, or by their age. To do so, use the filter() function which takes a conditional statement as its argument and displays only the rows that evaluate to true.
```{r filter_ex}

# this will only return the FIFA players that play for Real Madrid younger than 30
fifa_bio %>%
  select(Name, Age, Club) %>%
  filter(Club == "Real Madrid" & Age < 30) %>%
# by using the arrange() function, you can display the filtered players in age-order.
  arrange(Age)

```

In the fifa_bio table, monetary values are displayed in pounds. To make this dataset more accessible to Americans, we can "tidy" the data to convert it to USD. In order to add a new column to a dataframe, use the mutate() function.
```{r money_conv}

# based on the conversion rate at the time doing this project, 1 pound = 1.27 USD.
fifa_bio <- fifa_bio %>%
  # extracts the numeric magnitude from the string stored for both Value and Wage and then converts it to USD by using the mutate() function.
  separate(Value, c("currency", "monetary_value"), sep=1) %>%
  separate(monetary_value, c("magnitude", "millions"), sep=("M")) %>%
  transform(magnitude = as.numeric(magnitude)) %>%
  mutate(Value_USD = magnitude*1.27*1000000) %>%
  separate(Wage, c("currency2", "monetary_value2"), sep=1) %>%
  separate(monetary_value2, c("magnitude2", "millions2"), sep=("K")) %>%
  transform(magnitude2 = as.numeric(magnitude2)) %>%
  mutate(Salary_USD = magnitude2*1.27*1000) %>%
  select(ID, Name, Age, Club, Value_USD, Salary_USD, Position, Height, Weight)

```

To use weight as a numeric value, we must extract the lbs units to convert it to numeric.
```{r weight_conv}

fifa_bio <- fifa_bio %>%
  separate(Weight, c("Weight", "units"), sep=3) %>%
  transform(Weight = as.numeric(Weight)) %>%
  select(ID, Name, Age, Club, Value_USD, Salary_USD, Position, Height, Weight)

```

To use height as a numeric entity, we must convert it to inches and then convert it to numeric.
```{r height_conv}

fifa_bio <- fifa_bio %>%
  separate(Height, c("Feet", "Inches"), sep="'") %>%
  transform(Feet = as.numeric(Feet)) %>%
  transform(Inches = as.numeric(Inches)) %>%
  mutate(Height = ((Feet*12) + Inches)) %>%
  select(ID, Name, Age, Club, Value_USD, Salary_USD, Position, Height, Weight)
  
```

Since we are working with 2 separate datasets which both contain important information, we can combine the two datasets using a join function. In the pipeline below, fifa_bio and fifa_stats are joined based on matching player names. This will allow us to analyze biological attributes, like height and weight, against playing stats, like speed and acceleration, later on. Since some players have their stats recorded over a range of years, these tables must be joined on a composite key combo of their name and the ID of the entry, which varies based on their age.

```{r join} 

fifa_data <- fifa_bio %>%
  left_join(fifa_stats, by=c("Name" = "Name", "ID" = "ID"))

```

Now that the associated club is within the same dataset as all of the stats, we can take a summary of the data by averaging the 10 statistics (BallControl, Dribbling, Strength, SprintSpeed, Acceleration, Interceptions, Stamina, Vision, Marking, Balance) for each team by aggregating the data using group_by() and summarize().
```{r playerAvgs}

fifa_data %>%
  group_by(Club) %>%
  summarise(BallControl=mean(BallControl), Dribbling=mean(Dribbling), 
            Strength=mean(Strength), SprintSpeed=mean(SprintSpeed), 
            Acceleration=mean(Acceleration), Interceptions=mean(Interceptions), 
            Stamina=mean(Stamina), Vision=mean(Vision), Marking=mean(Marking), 
            Balance=mean(Balance))
  
```

Now that all of the attributes we wish to look at are in one table, we can do a basic visualization using the ggplot() function. Let's look at Stamina by Age. This plot will show a very basic dot plot by grouping the players together by age and averaging their stamina.
```{r basic_plot}

fifa_data %>%
  group_by(Age) %>%
  summarise(avg_stamina=mean(Stamina)) %>%
  ggplot(mapping=aes(x=Age, y=avg_stamina)) +
  geom_point() +
  labs(title="Football player stamina vs Age",
       x = "Age",
       y = "Average Stamina")
  
```

This plot shows that as age increases, average stamina of a futbol player decreases. This is one of the many helpful charts that are able to be made through the power of R. Data representation such as this is why R is important to data science, and knowing how to manipulate data in these ways is helpful for showing data to people to convince them of a trend. 

There are many other graphs you can make in R using ggplot, and it is essential to know how to make these graphs as visual data is the easiest way to convey a point or trend. Lets keep manipulating the football player stamina vs age statistics to see which graph conveys the trend that as age increases average stamina decreases. But first lets check if there are any missing entities in our table, as this may shift the data being displayed.

```{r  warning = FALSE}

summarized_data <- fifa_data %>%
  group_by(Age) %>%
  summarise(avg_stamina=mean(Stamina))
summarized_data
  
```

As you can see there is a lot of missing data in this table, and this can be for a variety of reasons. The way to handle missing data is dependant on why the data is missing. For instance if one weather station in a data set measures the temperature every day, while another weather station only measures the temperature every week, there will be a lot of missing data for temperatures of the days they didn't measure. The main two ways to handle missing data are to either remove the observations that are missing, or to impute the missing values by for example making every missing piece of data the average of all of the data that is present. Some missing data is missing at random, and some is missing systematically. In this case we should remove the missing data.

```{r  warning = FALSE}

summarized_data  %>%
  drop_na(avg_stamina)
summarized_data
  
```

Here we use the drop_na function to remove any instance of NA in our avg_stamina field, this way we are given a much cleaner data set that is easier to analyze. 

```{r  warning = FALSE}

summarized_data  %>%
  ggplot(mapping=aes(x=Age, y=avg_stamina)) +
  geom_bar(stat = "identity") +
  labs(title="Football player stamina vs Age",
       x = "Age",
       y = "Average Stamina")
  
```

Here we display the average stamina across age in a bar graph. This is a much more effective display of data as it is easier to see how average stamina changes as age grows older. Knowing which type of graph to use is essential for displaying data effectively. I highly suggest reading more on the subject through these sources. https://www.skillsyouneed.com/num/graphs-charts.html and https://blog.hubspot.com/marketing/types-of-graphs-for-data-visualization

Now we're going to be moving onto obtaining specific teams through regular expressions and string manipulation.

```{r  warning = FALSE}

clubs <- fifa_data %>% 
  group_by(Club) %>%
  summarize(Players = n_distinct(Name))

clubs
  
```

Here we have a table that shows us each club and the amount of players on each club. First we're going to omit the NA club as that data is not useful to us, and this will make the data more tidy.

```{r  warning = FALSE}
library(stringr)
clubs %>%
  drop_na(Club)
  
```

Regular expressions and string manipulations are important because lets say we wanted to only obtain information about teams with FC in front of their name, or CD in front of their name. How would we approach that? Filtering the table by typing out every club's name that starts out with FC or CD would be redundant and time consuming, this is where regular expressions come in.

```{r  warning = FALSE}

clubs %>%
  filter(str_detect(Club, "CD .*"))
  
```

Here we combine the str_detect function from the stringr library with the filter function in order to obtain teams only with the name that starts with CD. This is a much simpler way to filter out the rest of the teams without having to go through the struggle of typing out every team that starts with CD. The expression "CD .*" takes any name with CD in it and follows with a space followed by any amount of any character. The period matches any character, and the \* says there can be zero or more of any character. As you can see there is an issue here though, as teams with the name RCD are also included. To fix this is quite simple, the ^ character implicates that it must start with a certain string, and the $ character indicates it must end with a certain string.

```{r  warning = FALSE}

clubs %>%
  filter(str_detect(Club, "^CD .*"))
  
```

Here's our fixed data set using the ^ character to say that the club name must start with CD. There are many more intricacies and impressive things you can do with regular expressions in R and other languages, I highly suggest you read more on the subject here: http://www.hcbravo.org/IntroDataSci/bookdown-notes/text-and-dates.html

You can also test out your regular expressions on this website:
https://rubular.com/

The next topic we will be focusing on is Exploratory Data Analysis, which is a field about better understanding data we have gathered. This lets us make decisions about how to display data in order to properly visualize it to come to conclusions about said data. A big part of EDA is understanding central trends (mean), spread (variance), skew, and outliers. This helps us understand relationships between variables and ways to model them. Lets start off simply by visualizing single variables, such as the amount of players on a club team. We will mainly be looking at how some graphs don't fit certain data sets and other graphs fit much better. First we will try a histogram.

```{r  warning = FALSE}

clubs %>%
  ggplot(mapping = aes(x = Players)) + 
  geom_histogram() +
  labs(title="Count of players",
       x = "Player amount",
       y = "Amount of teams with that many players")
  
```

Here we can clearly see that a histogram doesn't represent the data well at all, we have no idea what it is trying to say and it doesn't convey any trend. Let's try a histogram instead.

```{r  warning = FALSE}

clubs %>%
  ggplot(aes(x = '', y = Players)) + 
  geom_boxplot()
  
```

The boxplot is a little better but we still have some work to do to make it effective. As you can see by this boxplot, simply graphing the number of players per team doesn't work when the data isn't tidy. This plot shows that there is a huge outlier from the NA team that skews all of the data to the right. This makes the data hard to visualize and therefore not productive to creating an effective visual represntation of this data. To fix this we must once again tidy the data.

```{r  warning = FALSE}

clubs %>%
  drop_na(Club) %>%
  ggplot(aes(x = '', y = Players)) + 
  geom_boxplot()
  
```

Here we have a much more effective display of data. A boxplot is effective at showing the mean, quartiles, outliers, and range in a data set. Here the range is around 18-33 as seen by the top of the boxplot and the bottom. The outliers are at the bottom represented by dots, and the quartiles are represented by the top and bottom part of the box. The mean is about 27 shown by the line through the box. This data generally tells us that most teams have at least 26 players on their team. Next we will be graphing distributions of height and weight to see if there are any correlations between the two.

```{r  warning = FALSE}

htwt <- fifa_bio %>%
  select(Name, Height, Weight)

htwt %>% head()

```

Here we have isolated the name of each player with just their height and weight so we can have a clean easy to read data set to manipulate and graph. A boxplot would not be an effective way to display this data and it's trends because the boxplot is limited to taking one variable or a group of one variable. Instead we will use a point graph to document each point of data.

```{r  warning = FALSE}

htwt %>%
  ggplot(aes(x=Height, y=Weight)) +
  geom_point()
  
```

In this graph you can see there is a general trend of as you become taller you tend to weigh more. The reason why the point graph looks like many lines of dots is because height is not continuous, you can either be 70 inches or 71 inches tall in this data set, there is no inbetween. A great way to represent this upward trend is by adding a line of best fit, otherwise known as a regression line to show the trend in this data directly. A regression line is calculated through the residual sum of squares which we will talk about later.

```{r  warning = FALSE}

htwt %>%
  ggplot(aes(x=Height, y=Weight)) +
  geom_point() + 
  geom_smooth(method=lm)
  
```

This graph is a much better representation of the data as it shows the tendency clearly on the blue line, which is an effective way of making a point about how height is directly related to weight and the taller you are the more you are going to weigh. 

Now something that a FIFA 19 gamer might be interested in is understanding how the different player attributes affect one another. For example, maybe we could test the relationships between Vision/Marking or BallControl/Stamina. Or maybe, according to you, it would seem likely that players who have a high Acceleration rating would also have a high Interceptions rating as they are better at rushing up to a player and stealing the ball from them. Luckily, there are functions in R from the broom library that allow us to put this hypothesis to the test.

```{r scott1,warning = FALSE}
library(broom)

gap_fit <- lm(Marking~Vision, data=fifa_stats)
tidy_gap_fit <- tidy(gap_fit)
tidy_gap_fit

gap_fit <- lm(BallControl~Stamina, data=fifa_stats)
tidy_gap_fit <- tidy(gap_fit)
tidy_gap_fit

gap_fit <- lm(Interceptions~SprintSpeed, data=fifa_stats)
tidy_gap_fit <- tidy(gap_fit)

tidy_gap_fit
```

We can use the lm function to determine whether or not there is a significant relationship between Interceptions and Sprint Speed.
What we find for the players in FIFA 19 is that there is a significant relationship between the two attributes. If we look the the
p-value in the table generated, we find an extremely small number. In this case, this p-value represents the probability in which we
mistakenly reject the hypothesis that Sprint Speed and Interceptions are not correlated. This is important to note as a small number
indicates that our hypothesis is correct.

In R, we also have functions that provide users with additional information about linear regression models.

```{r scott10, warning=FALSE}
gap_fit %>%
  glance() %>%
  select(r.squared, df)
```

In the code above, we use the glance() function to print out the r-squared value and the degrees of freedom of our linear regression model. The r-squared value is the proportion of the variance in the dependent variable that is predictable from the independent variable. The degrees of freedom represents the number of independent factors affecting the range of states in which a system may exist.

To read up more on r-squared values and their purpose, the following article is very informative
https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit

The next important step in developing our regression model is to test whether or not a linear model suits our data. In order to
properly test our current model, we can plot residuals as a function of the fitted values from our model. Once again we will be using
a function from the broom library, augment().

```{r scott13, warning = FALSE}
augmented_fit <- gap_fit %>%
  augment()
augmented_fit %>% head()
```

The table above shows all of the information we need to assess the linearity or non-linearity of our model. However, it may be easier to understand this data when displayed visually, plotting residuals against fitted values.

```{r scott16, warning = FALSE}
augmented_fit %>%
  ggplot(aes(x=.fitted,y=.resid)) +
    geom_point() + 
    labs(x="fitted", y="residual")
```

Even though we plotted our residuals against the fitted values, the data is still somewhat unorganized. When analyzing your regression model, it can be very helpful to add a line showing the trend of the data. We will do this by adding geom_smooth() to our plotting code.

```{r scott20, warning = FALSE}
augmented_fit %>%
  ggplot(aes(x=.fitted,y=.resid)) +
    geom_point() + 
    geom_smooth() +
    labs(x="fitted", y="residual")
```

When assessing the quality of our model using a residual plot, we want to see constant variance throughout the plot. However, as indicated by the regression line, our variance is far from constant, indicating that there is an issue with our regression model.

In addition to testing how two player attributes interact with each other, R allows us to use the lm() function to create multivariate regression models. Multiple linear regressions can be much more useful than linear regressions with two variables as it gives data scientists a better idea of the data systems. The following lists a couple examples of linear regression models. You will notice that as you add more variables the coefficients continue to change even when the some of the attributes used stay the same.

```{r scott25, warning = FALSE}
multi_gap_fit <- lm(Interceptions~1+Marking+BallControl, data=fifa_stats)
multi_gap_fit

multi_gap_fit <- lm(Interceptions~1+Vision+Marking+BallControl, data=fifa_stats)
multi_gap_fit

multi_gap_fit <- lm(Interceptions~1+Acceleration+Vision+Marking+BallControl, data=fifa_stats)
multi_gap_fit

multi_gap_fit <- lm(Interceptions~1+SprintSpeed+Acceleration+Vision+Marking+BallControl, data=fifa_stats)
multi_gap_fit
```

So far in our analysis of our data using regression models, we have only used continuous variables. However, how would we handle regression models that include categorical values such as the Position attribute in our fifa_bio dataframe? Variables will not always be continuous and it is important to understand how to correctly incorporate categorical attributes into your regression model.

Luckily, R functions make adding categorical attributes to our model pretty straightforward. What we first have to do is add attributes for each possible value of our categorical attribute but one.

```{r scott34, warning = FALSE}
fifa_bio <- fifa_bio %>%
  mutate(Position=factor(Position))
levels(fifa_bio$Position)
```

In the above example, we used factor() to break the Position attribute into all of its possible values. Then we simply used levels() to print out all of the values in our dataset for Position.

We can also use model.matrix() to look at what our new dataframe looks like.

```{r scott37, warning = FALSE}
fifa_df <- model.matrix(~Position, data=fifa_bio) %>% 
  as.data.frame() 

fifa_df %>%
  head()
```

We can use model.matrix again with a similar process to create a matrix including our new attributes comparing them to another attribute such as Value_USD. Let's look at an example of how we would implement this.

```{r scott40, warning = FALSE}
fifa_df <- model.matrix(~Value_USD+Age+Position+Value_USD:Position, data=fifa_bio) %>% 
  as.data.frame() 

fifa_df %>%
  head()
```

Now that we have seen different ways of handling categorical attributes in regression models, let us look at an approach to graphing data in order to focus on the effect a categorical attribute has on other attributes. In the following example, we will first look at the graphical relationship between Age and Value_USD. Then we will look at how we can add our categorical attribute to create a better graph.

```{r scott43, warning = FALSE}
fifa_bio %>%
  ggplot(aes(x=Age, y=Value_USD)) +
    geom_point() +
    geom_smooth(method=lm)

fifa_bio %>%
  ggplot(aes(x=Age, y=Value_USD,color=Position)) +
    geom_point() +
    geom_smooth(method=lm)
```

Here the categorical attributes show each different position's different age vs value rates with linear regression lines to show clear trends in the data. 
All of this data and data manipulation above is important to understand because in order to convey a point effectively, proper data visualization and clean and tidy data is incredibly important. FIFA 2019 data is also important as it relates heavily to real soccer statistics as the makers of the game have created each player's statistics by using their own algorithms to determine each players skills. Data science is crucial to understanding the world we live in and it's trends.
